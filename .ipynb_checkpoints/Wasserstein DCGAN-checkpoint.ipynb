{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import scipy.misc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCH = 5000\n",
    "HEIGHT, WIDTH, CHANNEL = 28,28,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(): \n",
    "    from keras.datasets import mnist\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "    num_images = len(X_train)\n",
    "    return image_batch , num_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input, random_dim, is_train, reuse=False): \n",
    "\n",
    "    with tf.variable_scope('gen') as scope: \n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        w1 = tf.get_variable('w1', shape=[random_dim, 1024], dtype=tf.float32,\n",
    "                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b1 =  b1 = tf.get_variable('b1', shape=[1024], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(1.0))\n",
    "        flat_conv1 = tf.add(tf.matmul(input , w1) , b1 , name = 'flat_conv1')\n",
    "        act1 = tf.nn.tanh(flat_conv1, name='act1')\n",
    "\n",
    "        dense1 = tf.layers.dense(bias_initializer=tf.ones_initializer(),inputs=act1, units=128*7*7, activation=tf.nn.tanh , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "        bn1 = tf.contrib.layers.batch_norm(dense1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "        act2 = tf.nn.tanh(bn1, name='act1')\n",
    "\n",
    "        conv1 = tf.reshape(act2, shape=[-1,7,7,128], name='conv1')\n",
    "        up1 = tf.keras.layers.UpSampling2D(size = (2,2))\n",
    "\n",
    "        conv2 = tf.layers.conv2d(bias_initializer=tf.ones_initializer(),inputs=up1,filters=64,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.tanh , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "        up2 = tf.keras.layers.UpSampling2D(size = (2,2))\n",
    "        conv3 = tf.layers.conv2d(bias_initializer=tf.ones_initializer(),inputs=up2,filters =1,kernel_size=[5, 5],padding= \"same\",activation=tf.nn.tanh , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "              \n",
    "        return conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def discriminator(input, is_train, reuse=False):\n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv1 = tf.layers.conv2d(input, 64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                 name='conv1',bias_initializer=tf.ones_initializer())\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
    "        act1 = tf.nn.tanh(conv1, n='act1')\n",
    "         #Convolution, activation, bias, repeat! \n",
    "        conv2 = tf.layers.conv2d(act1, 128, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                 name='conv2',bias_initializer=tf.ones_initializer())\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = tf.nn.tanh(bn2, n='act2')\n",
    "        \n",
    "        dim = int(np.prod(act2.get_shape()[1:]))\n",
    "        fc1 = tf.reshape(act2, shape=[-1, dim], name='fc1')\n",
    "        \n",
    "        dense1 = tf.layers.dense(bias_initializer=tf.ones_initializer(),inputs=fc1, units=1024, activation=tf.nn.relu , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "        dense2 = tf.layers.dense(bias_initializer=tf.ones_initializer(),inputs=dense2, units=1, activation=tf.nn.sigmoid , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    return dense2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    random_dim = 100\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        #real and fake image placholders\n",
    "        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
    "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    # wgan\n",
    "    fake_image = generator(random_input, random_dim, is_train)\n",
    "    \n",
    "    real_result = discriminator(real_image, is_train)\n",
    "    fake_result = discriminator(fake_image, is_train, reuse=True)\n",
    "    \n",
    "    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  # This optimizes the discriminator.\n",
    "    g_loss = -tf.reduce_mean(fake_result)  # This optimizes the generator.\n",
    "            \n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'gen' in var.name]\n",
    "    # test\n",
    "    # print(d_vars)\n",
    "    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
    "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
    "    # clip discriminator weights\n",
    "    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
    "\n",
    "    \n",
    "    batch_size = BATCH_SIZE\n",
    "    image_batch, samples_num = process_data()\n",
    "    \n",
    "    batch_num = int(samples_num / batch_size)\n",
    "    total_batch = 0\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # continue training\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
    "    saver.restore(sess, save_path)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    print('total training sample num:%d' % samples_num)\n",
    "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
    "    print('start training...')\n",
    "    for i in range(EPOCH):\n",
    "        print(i)\n",
    "        for j in range(batch_num):\n",
    "            print(j)\n",
    "            d_iters = 5\n",
    "            g_iters = 1\n",
    "\n",
    "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            for k in range(d_iters):\n",
    "                print(k)\n",
    "                train_image = sess.run(image_batch)\n",
    "                #wgan clip weights\n",
    "                sess.run(d_clip)\n",
    "                \n",
    "                # Update the discriminator\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n",
    "\n",
    "            # Update the generator\n",
    "            for k in range(g_iters):\n",
    "                # train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={random_input: train_noise, is_train: True})\n",
    "\n",
    "            # print 'train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss)\n",
    "            \n",
    "        # save check point every 500 epoch\n",
    "        if i%500 == 0:\n",
    "            if not os.path.exists('./model/' + version):\n",
    "                os.makedirs('./model/' + version)\n",
    "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
    "        if i%50 == 0:\n",
    "            # save images\n",
    "            if not os.path.exists(newPoke_path):\n",
    "                os.makedirs(newPoke_path)\n",
    "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
    "            # imgtest = imgtest * 255.0\n",
    "            # imgtest.astype(np.uint8)\n",
    "            save_images(imgtest, [8,8] ,newPoke_path + '/epoch' + str(i) + '.jpg')\n",
    "            \n",
    "            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n",
    "    coord.request_stop()\n",
    "coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
